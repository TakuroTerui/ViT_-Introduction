{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "APhyEsoLYxH9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMlp(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vec_length: int=16,\n",
        "        hidden_unit_1: int=8,\n",
        "        hidden_unit_2: int=2):\n",
        "        \"\"\"\n",
        "        引数：\n",
        "            vec_length：入力ベクトルの長さ\n",
        "            hidden_unit_1：1つ目の線形層のニューロン層\n",
        "            hidden_unit_2：2つ目の線形層のニューロン層\n",
        "        \"\"\"\n",
        "        super(SimpleMlp, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(vec_length, hidden_unit_1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_unit_1, hidden_unit_2)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播は線形層→ReLU→線形層の順番\n",
        "        引数：\n",
        "            x： 入力（B, D_in）\n",
        "                B：バッチサイズ、D_in：ベクトルの長さ\n",
        "        返り値：\n",
        "            out： 出力（B, D_out）\n",
        "                B：バッチサイズ、D_out：ベクトルの長さ\n",
        "        \"\"\"\n",
        "        out = self.layer1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "JrjUrMPNZ1Wh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec_length = 16\n",
        "hidden_unit_1 = 8\n",
        "hidden_unit_2 = 2\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "x = torch.randn(batch_size, vec_length)\n",
        "net = SimpleMlp(vec_length, hidden_unit_1, hidden_unit_2)\n",
        "out = net(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVLr66Cwb9OF",
        "outputId": "66282479-122e-4356-fb87-f49fef69d9ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTInputLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel:int=3,\n",
        "        emb_dim:int=384,\n",
        "        num_patch_row:int=2,\n",
        "        image_size:int=32\n",
        "    ):\n",
        "        \"\"\"\n",
        "        引数：\n",
        "            in_channel：入力画像のチャンネル数\n",
        "            emb_dim：畳み込み後のベクトルの長さ\n",
        "            num_path_row：高さ方向のパッチの数。例は2×2であるため、2をデフォルト値とした\n",
        "            image_size:：入力画像の1辺の長さ、入力画像の高さと幅は同じであると仮定した\n",
        "        \"\"\"\n",
        "        super(ViTInputLayer, self).__init__()\n",
        "        self.in_channels = in_channel\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_patch_row = num_patch_row\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # パッチの数\n",
        "        # 例：入力画像を2×2のパッチに分ける場合、num_patchは\n",
        "        self.num_patch = self.num_patch_row ** 2\n",
        "\n",
        "        # パッチの大きさ\n",
        "        # 例：入力画像の1辺の大きさが32の場合、patch_sizeは16\n",
        "        self.patch_size = int(self.image_size // self.num_patch_row)\n",
        "\n",
        "        # 入力画像のパッチへの分割＆パッチの埋め込みを一気に行う\n",
        "        self.patch_emb_layer = nn.Conv2d(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.emb_dim,\n",
        "            kernel_size=self.patch_size,\n",
        "            stride=self.patch_size\n",
        "        )\n",
        "\n",
        "        # クラストークン\n",
        "        self.cls_token = nn.Parameter(\n",
        "            torch.randn(1, 1, emb_dim)\n",
        "        )\n",
        "\n",
        "        # 位置埋め込み\n",
        "        # クラストークンが先頭に結合されているため、\n",
        "        # 長さ emb_dimの埋め込みベクトルを（パッチ数＋1）個用意\n",
        "        self.pos_emb = nn.Parameter(\n",
        "            torch.randn(1, self.num_patch+1, emb_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        引数：\n",
        "            x：　入力画像、形状は（B、C、H、W）\n",
        "        返り値：\n",
        "            z_0：ViTへの入力、形状は（B、N、D）\n",
        "        \"\"\"\n",
        "        # パッチの埋め込み＆flatten\n",
        "        # パッチの埋め込み（B、C、H、W）->（B、D、H/P、W/P）\n",
        "        # ここで、Pはパッチ1辺の長さ\n",
        "        z_0 = self.patch_emb_layer(x)\n",
        "\n",
        "        # パッチのflatten（B、D、H/P、W/P）->（B、D、Np）\n",
        "        # ここで、Npはパッチの数（=H*W/P^2）\n",
        "        z_0 = z_0.flatten(2)\n",
        "\n",
        "        # 軸の入れ替え（B、D、Np）->（B、Np、D）\n",
        "        z_0 = z_0.transpose(1, 2)\n",
        "\n",
        "        # パッチの埋め込みの先頭にクラストークンを結合\n",
        "        # （B、Np、D）->(B, N, D)\n",
        "        # N = (Np + 1)であることに留意\n",
        "        # また、cls_tokenの形状は(1, 1, D)であるため、\n",
        "        # repeatメソッドによって(B, 1, D)に変換してからパッチの埋め込みとの結合を行う\n",
        "        z_0 = torch.cat(\n",
        "            [self.cls_token.repeat(repeats=(x.size(0), 1, 1)), z_0], dim=1\n",
        "        )\n",
        "\n",
        "        # 位置埋め込みの加算\n",
        "        # (B, N, D)->(B, N, D)\n",
        "        z_0 = z_0 + self.pos_emb\n",
        "\n",
        "        return z_0"
      ],
      "metadata": {
        "id": "DOXUF2JHcYm1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, channel, height, width = 2, 3, 32, 32\n",
        "x = torch.randn(batch_size, channel, height, width)\n",
        "input_layer = ViTInputLayer(num_patch_row=2)\n",
        "z_0 = input_layer(x)\n",
        "\n",
        "print(z_0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_9ykLmSlw94",
        "outputId": "7aa8d9c6-95c7-4aa9-bba4-0ab7b3df42af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8Bo-SN2mLdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}